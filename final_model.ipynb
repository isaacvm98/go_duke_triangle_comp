{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dcdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05201562",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f511f329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Elo_Diff_Squared'] = df['Elo_Last_Diff'] ** 2\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Elo_Diff_Cubed'] = df['Elo_Last_Diff'] ** 3\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Elo_Mean_Diff_Squared'] = df['Elo_Mean_Diff'] ** 2\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Elo_Trend_Diff_Squared'] = df['Elo_Trend_Diff'] ** 2\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['POM_x_Elo'] = df['POM_RankDiff'] * df['Elo_Last_Diff']\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:9: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Barthag_x_Elo'] = df['Barthag_Diff'] * df['Elo_Last_Diff']\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['POM_Strength_x_Elo'] = df['POM_StrengthDiff'] * df['Elo_Last_Diff']\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Elo_x_Momentum'] = df['Elo_Last_Diff'] * df['Last5_PointDiff_Diff']\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['AdjOE_x_Elo'] = df['AdjOE_Diff'] * df['Elo_Last_Diff']\n",
      "C:\\Users\\isaac\\AppData\\Local\\Temp\\ipykernel_18204\\2407135577.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['AdjDE_x_Elo'] = df['AdjDE_Diff'] * df['Elo_Last_Diff']\n"
     ]
    }
   ],
   "source": [
    "# Calculate Elo interactions\n",
    "df['Elo_Diff_Squared'] = df['Elo_Last_Diff'] ** 2\n",
    "df['Elo_Diff_Cubed'] = df['Elo_Last_Diff'] ** 3\n",
    "df['Elo_Mean_Diff_Squared'] = df['Elo_Mean_Diff'] ** 2\n",
    "df['Elo_Trend_Diff_Squared'] = df['Elo_Trend_Diff'] ** 2\n",
    "\n",
    "# Calculate cross interactions\n",
    "df['POM_x_Elo'] = df['POM_RankDiff'] * df['Elo_Last_Diff']\n",
    "df['Barthag_x_Elo'] = df['Barthag_Diff'] * df['Elo_Last_Diff']\n",
    "\n",
    "# Optional: Add more cross interactions that might help with blowouts\n",
    "df['POM_Strength_x_Elo'] = df['POM_StrengthDiff'] * df['Elo_Last_Diff']\n",
    "df['Elo_x_Momentum'] = df['Elo_Last_Diff'] * df['Last5_PointDiff_Diff']\n",
    "df['AdjOE_x_Elo'] = df['AdjOE_Diff'] * df['Elo_Last_Diff']\n",
    "df['AdjDE_x_Elo'] = df['AdjDE_Diff'] * df['Elo_Last_Diff']\n",
    "\n",
    "# Feature groups dictionary (updated)\n",
    "feature_groups = {\n",
    "    'elo': [\n",
    "        'Elo_Mean_Home', 'Elo_Median_Home', 'Elo_Std_Home', 'Elo_Min_Home', \n",
    "        'Elo_Max_Home', 'Elo_Last_Home', 'Elo_Trend_Home',\n",
    "        'Elo_Mean_Away', 'Elo_Median_Away', 'Elo_Std_Away', 'Elo_Min_Away',\n",
    "        'Elo_Max_Away', 'Elo_Last_Away', 'Elo_Trend_Away',\n",
    "        'Elo_Last_Diff', 'Elo_Mean_Diff', 'Elo_Trend_Diff'\n",
    "    ],\n",
    "    \n",
    "    'elo_interactions': [\n",
    "        'Elo_Diff_Squared',\n",
    "        'Elo_Diff_Cubed', \n",
    "        'Elo_Mean_Diff_Squared',\n",
    "        'Elo_Trend_Diff_Squared'\n",
    "    ],\n",
    "    \n",
    "    'cross_interactions': [\n",
    "        'POM_x_Elo',\n",
    "        'Barthag_x_Elo',\n",
    "        'POM_Strength_x_Elo',\n",
    "        'Elo_x_Momentum',\n",
    "        'AdjOE_x_Elo',\n",
    "        'AdjDE_x_Elo'\n",
    "    ],\n",
    "    \n",
    "    'pom_ranking': [\n",
    "        'Home_POM_Rank', 'Home_POM_RankDay', 'Away_POM_Rank', 'Away_POM_RankDay',\n",
    "        'POM_RankDiff', 'Home_POM_Strength', 'Away_POM_Strength', 'POM_StrengthDiff',\n",
    "        'Home_POM_LogStrength', 'Away_POM_LogStrength', 'Home_POM_Strength2', \n",
    "        'Away_POM_Strength2', 'Home_POM_IsTop25', 'Away_POM_IsTop25',\n",
    "        'Home_POM_IsTop50', 'Away_POM_IsTop50', 'POM_BothTop25', 'POM_BothTop50',\n",
    "        'POM_RankDiff_Squared', 'RankDiff_Magnitude', 'IsHugeMismatch', \n",
    "        'IsBigMismatch', 'Elite_vs_Weak', 'Weak_vs_Elite'\n",
    "    ],\n",
    "    \n",
    "    'torvik_kenpom': [\n",
    "        'Home_AdjOE', 'Home_AdjDE', 'Home_Barthag', 'Home_EFG%', 'Home_EFGD%',\n",
    "        'Home_TOR', 'Home_TORD', 'Home_ORB', 'Home_DRB', 'Home_FTR', 'Home_FTRD',\n",
    "        'Home_2P%', 'Home_2P%D', 'Home_3P%', 'Home_3P%D', 'Home_3PR', 'Home_3PRD',\n",
    "        'Home_Adj T.', 'Home_WAB',\n",
    "        'Away_AdjOE', 'Away_AdjDE', 'Away_Barthag', 'Away_EFG%', 'Away_EFGD%',\n",
    "        'Away_TOR', 'Away_TORD', 'Away_ORB', 'Away_DRB', 'Away_FTR', 'Away_FTRD',\n",
    "        'Away_2P%', 'Away_2P%D', 'Away_3P%', 'Away_3P%D', 'Away_3PR', 'Away_3PRD',\n",
    "        'Away_Adj T.', 'Away_WAB',\n",
    "        'AdjOE_Diff', 'AdjDE_Diff', 'Barthag_Diff', 'EFG%_Diff', 'EFGD%_Diff',\n",
    "        'TOR_Diff', 'TORD_Diff', 'ORB_Diff', 'DRB_Diff', 'FTR_Diff', 'FTRD_Diff',\n",
    "        '2P%_Diff', '2P%D_Diff', '3P%_Diff', '3P%D_Diff', '3PR_Diff', '3PRD_Diff',\n",
    "        'Adj T._Diff', 'WAB_Diff', 'Barthag_Mismatch'\n",
    "    ],\n",
    "    \n",
    "    'momentum_last5': [\n",
    "        'Last5_WinPct', 'Last5_PointsMean', 'Last5_OppPointsMean', 'Last5_PointDiff',\n",
    "        'Last5_NumGames', 'Last5_FGPct', 'Last5_3pPct', 'Last5_FTPct', 'Last5_eFGPct',\n",
    "        'Last5_TSPct', 'Last5_OffEff', 'Last5_Pace', 'Last5_AstTORatio', 'Last5_AstRate',\n",
    "        'Last5_TORatePer100', 'Last5_FTRate', 'Last5_3pRate', 'Last5_ORebRate',\n",
    "        'Last5_DRebRate', 'Last5_TotalRebRate', 'Last5_RebPerGame', 'Last5_DefEff',\n",
    "        'Last5_OppeFGPct', 'Last5_OppFGPct', 'Last5_Opp3pPct', 'Last5_BlkRate',\n",
    "        'Last5_StlRatePer100', 'Last5_ForcedTORate', 'Last5_NetEff',\n",
    "        'Last5_Recent3WinPct', 'Last5_Recent3PointDiff',\n",
    "        'Last5_WinPct_L5_Away', 'Last5_PointsMean_L5_Away', 'Last5_OppPointsMean_L5_Away',\n",
    "        'Last5_PointDiff_L5_Away', 'Last5_NumGames_L5_Away', 'Last5_FGPct_L5_Away',\n",
    "        'Last5_3pPct_L5_Away', 'Last5_FTPct_L5_Away', 'Last5_eFGPct_L5_Away',\n",
    "        'Last5_TSPct_L5_Away', 'Last5_OffEff_L5_Away', 'Last5_Pace_L5_Away',\n",
    "        'Last5_AstTORatio_L5_Away', 'Last5_AstRate_L5_Away', 'Last5_TORatePer100_L5_Away',\n",
    "        'Last5_FTRate_L5_Away', 'Last5_3pRate_L5_Away', 'Last5_ORebRate_L5_Away',\n",
    "        'Last5_DRebRate_L5_Away', 'Last5_TotalRebRate_L5_Away', 'Last5_RebPerGame_L5_Away',\n",
    "        'Last5_DefEff_L5_Away', 'Last5_OppeFGPct_L5_Away', 'Last5_OppFGPct_L5_Away',\n",
    "        'Last5_Opp3pPct_L5_Away', 'Last5_BlkRate_L5_Away', 'Last5_StlRatePer100_L5_Away',\n",
    "        'Last5_ForcedTORate_L5_Away', 'Last5_NetEff_L5_Away', 'Last5_Recent3WinPct_L5_Away',\n",
    "        'Last5_Recent3PointDiff_L5_Away',\n",
    "        'Last5_WinPct_Diff', 'Last5_PointDiff_Diff'\n",
    "    ],\n",
    "    \n",
    "    'momentum_last10': [\n",
    "        'Last10_WinPct', 'Last10_PointsMean', 'Last10_OppPointsMean', 'Last10_PointDiff',\n",
    "        'Last10_NumGames', 'Last10_FGPct', 'Last10_3pPct', 'Last10_FTPct', 'Last10_eFGPct',\n",
    "        'Last10_TSPct', 'Last10_OffEff', 'Last10_Pace', 'Last10_AstTORatio', 'Last10_AstRate',\n",
    "        'Last10_TORatePer100', 'Last10_FTRate', 'Last10_3pRate', 'Last10_ORebRate',\n",
    "        'Last10_DRebRate', 'Last10_TotalRebRate', 'Last10_RebPerGame', 'Last10_DefEff',\n",
    "        'Last10_OppeFGPct', 'Last10_OppFGPct', 'Last10_Opp3pPct', 'Last10_BlkRate',\n",
    "        'Last10_StlRatePer100', 'Last10_ForcedTORate', 'Last10_NetEff',\n",
    "        'Last10_Recent3WinPct', 'Last10_Recent3PointDiff',\n",
    "        'Last10_WinPct_L10_Away', 'Last10_PointsMean_L10_Away', 'Last10_OppPointsMean_L10_Away',\n",
    "        'Last10_PointDiff_L10_Away', 'Last10_NumGames_L10_Away', 'Last10_FGPct_L10_Away',\n",
    "        'Last10_3pPct_L10_Away', 'Last10_FTPct_L10_Away', 'Last10_eFGPct_L10_Away',\n",
    "        'Last10_TSPct_L10_Away', 'Last10_OffEff_L10_Away', 'Last10_Pace_L10_Away',\n",
    "        'Last10_AstTORatio_L10_Away', 'Last10_AstRate_L10_Away', 'Last10_TORatePer100_L10_Away',\n",
    "        'Last10_FTRate_L10_Away', 'Last10_3pRate_L10_Away', 'Last10_ORebRate_L10_Away',\n",
    "        'Last10_DRebRate_L10_Away', 'Last10_TotalRebRate_L10_Away', 'Last10_RebPerGame_L10_Away',\n",
    "        'Last10_DefEff_L10_Away', 'Last10_OppeFGPct_L10_Away', 'Last10_OppFGPct_L10_Away',\n",
    "        'Last10_Opp3pPct_L10_Away', 'Last10_BlkRate_L10_Away', 'Last10_StlRatePer100_L10_Away',\n",
    "        'Last10_ForcedTORate_L10_Away', 'Last10_NetEff_L10_Away', 'Last10_Recent3WinPct_L10_Away',\n",
    "        'Last10_Recent3PointDiff_L10_Away',\n",
    "        'Last10_WinPct_Diff', 'Last10_PointDiff_Diff'\n",
    "    ],\n",
    "    \n",
    "    'season_stats': [\n",
    "        'PointsMean_Home', 'PointsMedian_Home', 'OppPointsMean_Home', 'FGAMean_Home',\n",
    "        'FGAMedian_Home', 'FGA3Mean_Home', 'FTAMean_Home', 'ORMean_Home', 'DRMean_Home',\n",
    "        'AstMean_Home', 'TOMean_Home', 'StlMean_Home', 'BlkMean_Home', 'OppFGAMean_Home',\n",
    "        'OppTOMean_Home', 'PointDiff_Home',\n",
    "        'PointsMean_Away', 'PointsMedian_Away', 'OppPointsMean_Away', 'FGAMean_Away',\n",
    "        'FGAMedian_Away', 'FGA3Mean_Away', 'FTAMean_Away', 'ORMean_Away', 'DRMean_Away',\n",
    "        'AstMean_Away', 'TOMean_Away', 'StlMean_Away', 'BlkMean_Away', 'OppFGAMean_Away',\n",
    "        'OppTOMean_Away', 'PointDiff_Away',\n",
    "        'PointsMean_Diff', 'FGAMean_Diff', 'FGA3Mean_Diff', 'FTAMean_Diff', 'ORMean_Diff',\n",
    "        'DRMean_Diff', 'AstMean_Diff', 'TOMean_Diff', 'StlMean_Diff', 'BlkMean_Diff',\n",
    "        'PointDiff_Diff'\n",
    "    ],\n",
    "    \n",
    "    'glm_quality': [\n",
    "        'GLM_Quality_Home', 'GLM_Quality_Away', 'GLM_Quality_Diff'\n",
    "    ],\n",
    "    \n",
    "    'composite_features': [\n",
    "        'Mismatch_x_Form', 'Momentum_Quality', 'Possession_Control_Diff',\n",
    "        '3P_Threat_Diff'\n",
    "    ],\n",
    "\n",
    "    'flags': [\n",
    "        'IsACCGame', 'HasACCTeam', 'sample_weight', 'distance_miles', 'IsConferenceGame'\n",
    "    ],\n",
    "    \n",
    "    'metadata': [\n",
    "        'Season', 'DayNum', 'HomeTeamID', 'AwayTeamID', 'IsNeutral', 'IsHome',\n",
    "        'HomeConf', 'AwayConf'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1d67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_acc_focused_splits(df_model_clean, feature_cols,\n",
    "                               train_seasons=range(2015, 2023),\n",
    "                               val_seasons=[2023, 2024],\n",
    "                               test_season=2025,\n",
    "                               target_day_range=(90, 120)):\n",
    "    \"\"\"\n",
    "    Create splits focused on ACC conference games in the last 30 days\n",
    "    \"\"\"\n",
    "\n",
    "    train_data = df_model_clean[\n",
    "        (df_model_clean['Season'].isin(train_seasons))\n",
    "    ].copy()\n",
    "    \n",
    "    val_data = df_model_clean[\n",
    "        (df_model_clean['Season'].isin(val_seasons)) &\n",
    "        (df_model_clean['DayNum'] >= target_day_range[0]) &\n",
    "        (df_model_clean['DayNum'] <= target_day_range[1]) &\n",
    "        (df_model_clean['IsACCGame'] == 1)  # ACC games only\n",
    "    ].copy()\n",
    "    \n",
    "    test_data = df_model_clean[\n",
    "        (df_model_clean['Season'] == test_season) &\n",
    "        (df_model_clean['DayNum'] >= target_day_range[0]) &\n",
    "        (df_model_clean['DayNum'] <= target_day_range[1]) &\n",
    "        (df_model_clean['IsACCGame'] == 1)  # ACC games only\n",
    "    ].copy()\n",
    "    X_train = train_data[feature_cols].copy()\n",
    "    y_train = train_data['HomeSpread'].copy()\n",
    "    \n",
    "    X_val = val_data[feature_cols].copy()\n",
    "    y_val = val_data['HomeSpread'].copy()\n",
    "    \n",
    "    X_test = test_data[feature_cols].copy()\n",
    "    y_test = test_data['HomeSpread'].copy()\n",
    "    \n",
    "    train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "    X_train = X_train[train_mask]\n",
    "    y_train = y_train[train_mask]\n",
    "    \n",
    "    val_mask = ~(X_val.isnull().any(axis=1) | y_val.isnull())\n",
    "    X_val = X_val[val_mask]\n",
    "    y_val = y_val[val_mask]\n",
    "    \n",
    "    test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "    X_test = X_test[test_mask]\n",
    "    y_test = y_test[test_mask]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ce8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# import itertools\n",
    "\n",
    "# def test_feature_combinations_loso(df, feature_groups, max_group_size=None, \n",
    "#                                    test_seasons=range(2018, 2026)):\n",
    "#     \"\"\"\n",
    "#     Test all possible combinations of feature groups using LOSO CV\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Exclude metadata from combinations\n",
    "#     testable_groups = {k: v for k, v in feature_groups.items() \n",
    "#                       if k not in ['flags']}\n",
    "    \n",
    "#     group_names = list(testable_groups.keys())\n",
    "#     results = []\n",
    "    \n",
    "#     if max_group_size is None:\n",
    "#         max_group_size = len(group_names)\n",
    "    \n",
    "    \n",
    "#     # Test each combination size\n",
    "#     for r in range(1, max_group_size + 1):\n",
    "        \n",
    "#         for combo in itertools.combinations(group_names, r):\n",
    "#             # Combine features from selected groups\n",
    "#             feature_cols = []\n",
    "#             for group in combo:\n",
    "#                 feature_cols.extend(testable_groups[group])\n",
    "            \n",
    "#             # Remove duplicates while preserving order\n",
    "#             feature_cols = list(dict.fromkeys(feature_cols))\n",
    "\n",
    "            \n",
    "#             try:\n",
    "#                 # Run LOSO CV\n",
    "#                 seasonal_maes = {}\n",
    "                \n",
    "#                 for test_yr in test_seasons:\n",
    "#                     # Split Data\n",
    "#                     train_df = df[df['Season'] != test_yr].copy()\n",
    "#                     test_df = df[\n",
    "#                         (df['Season'] == test_yr) & \n",
    "#                         (df['IsACCGame'] == 1) & \n",
    "#                         (df['DayNum'].between(90, 120))\n",
    "#                     ].copy()\n",
    "                    \n",
    "                    \n",
    "#                     # Prep X and y\n",
    "#                     X_train = train_df[feature_cols]\n",
    "#                     y_train = train_df['HomeSpread']\n",
    "#                     X_test = test_df[feature_cols]\n",
    "#                     y_test = test_df['HomeSpread']\n",
    "                    \n",
    "#                     # Handle missing values\n",
    "#                     train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "#                     X_train = X_train[train_mask]\n",
    "#                     y_train = y_train[train_mask]\n",
    "                    \n",
    "#                     test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "#                     X_test = X_test[test_mask]\n",
    "#                     y_test = y_test[test_mask]\n",
    "                    \n",
    "                    \n",
    "#                     # Recency weighting\n",
    "#                     weights = train_df.loc[train_mask, 'Season'].apply(\n",
    "#                         lambda x: 2.0 if x >= (test_yr - 3) else 1.0\n",
    "#                     )\n",
    "                    \n",
    "#                     # Initialize DMatrix\n",
    "#                     dtrain = xgb.DMatrix(X_train, label=y_train, weight=weights, \n",
    "#                                         feature_names=feature_cols)\n",
    "#                     dtest = xgb.DMatrix(X_test, label=y_test, feature_names=feature_cols)\n",
    "                    \n",
    "#                     # Parameters\n",
    "#                     params = {\n",
    "#                         'objective': 'reg:squarederror',\n",
    "#                         'eval_metric': 'mae',\n",
    "#                         'eta': 0.05,\n",
    "#                         'max_depth': 6,\n",
    "#                         'subsample': 0.8,\n",
    "#                         'colsample_bytree': 0.8,\n",
    "#                         'gamma': 0.1,\n",
    "#                         'alpha': 0.1,\n",
    "#                         'seed': 42\n",
    "#                     }\n",
    "                    \n",
    "#                     # Train\n",
    "#                     model = xgb.train(\n",
    "#                         params,\n",
    "#                         dtrain,\n",
    "#                         num_boost_round=1000,\n",
    "#                         evals=[(dtrain, 'train'), (dtest, 'eval')],\n",
    "#                         early_stopping_rounds=50,\n",
    "#                         verbose_eval=False\n",
    "#                     )\n",
    "                    \n",
    "#                     # Evaluate\n",
    "#                     preds = model.predict(dtest)\n",
    "#                     mae = mean_absolute_error(y_test, preds)\n",
    "#                     seasonal_maes[test_yr] = mae\n",
    "                \n",
    "#                 # Aggregate results\n",
    "#                 if len(seasonal_maes) > 0:\n",
    "#                     mean_mae = np.mean(list(seasonal_maes.values()))\n",
    "#                     std_mae = np.std(list(seasonal_maes.values()))\n",
    "                    \n",
    "#                     results.append({\n",
    "#                         'groups': ' + '.join(combo),\n",
    "#                         'num_groups': len(combo),\n",
    "#                         'num_features': len(feature_cols),\n",
    "#                         'mean_mae': mean_mae,\n",
    "#                         'std_mae': std_mae,\n",
    "#                         **{f'mae_{yr}': seasonal_maes.get(yr, np.nan) \n",
    "#                            for yr in test_seasons}\n",
    "#                     })\n",
    "                    \n",
    "#                     print(f\"  Mean MAE: {mean_mae:.3f} ± {std_mae:.3f}\")\n",
    "#                     print(f\"  Yearly: {', '.join([f'{yr}: {mae:.2f}' for yr, mae in seasonal_maes.items()])}\")\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"  ERROR: {str(e)}\")\n",
    "#                 continue\n",
    "    \n",
    "#     # Convert to DataFrame and sort\n",
    "#     results_df = pd.DataFrame(results)\n",
    "#     results_df = results_df.sort_values('mean_mae')\n",
    "    \n",
    "#     return results_df\n",
    "\n",
    "\n",
    "# # Run the test\n",
    "# print(\"Running LOSO CV feature combination testing...\")\n",
    "# results_df = test_feature_combinations_loso(\n",
    "#     df, \n",
    "#     feature_groups,\n",
    "#     max_group_size=3,  # Start with up to 3 groups\n",
    "#     test_seasons=range(2020, 2026)  # Recent seasons only\n",
    "# )\n",
    "\n",
    "# # Display results\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"TOP 20 FEATURE COMBINATIONS BY MEAN MAE (LOSO CV)\")\n",
    "# print(\"=\"*80)\n",
    "# print(results_df.head(20).to_string(index=False))\n",
    "\n",
    "# # Year-by-year stability analysis\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"STABILITY ANALYSIS - Top 5 Models\")\n",
    "# print(\"=\"*80)\n",
    "# for idx, row in results_df.head(5).iterrows():\n",
    "#     print(f\"\\n{row['groups']}:\")\n",
    "#     print(f\"  Mean: {row['mean_mae']:.3f} ± {row['std_mae']:.3f}\")\n",
    "#     yearly_maes = [row[f'mae_{yr}'] for yr in range(2020, 2026) \n",
    "#                    if f'mae_{yr}' in row and not pd.isna(row[f'mae_{yr}'])]\n",
    "#     if yearly_maes:\n",
    "#         print(f\"  Range: [{min(yearly_maes):.2f}, {max(yearly_maes):.2f}]\")\n",
    "#         print(f\"  Coefficient of Variation: {row['std_mae']/row['mean_mae']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38513392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LassoCV, Lasso\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def lasso_feature_selection(df, feature_groups, test_seasons=range(2020, 2026)):\n",
    "#     \"\"\"\n",
    "#     Use LASSO regression with LOSO CV to select features\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Get all features except metadata\n",
    "#     all_features = []\n",
    "#     for group_name, features in feature_groups.items():\n",
    "#         if group_name not in ['metadata']:\n",
    "#             all_features.extend(features)\n",
    "    \n",
    "#     all_features = list(dict.fromkeys(all_features))  # Remove duplicates\n",
    "    \n",
    "#     print(f\"Starting with {len(all_features)} features\")\n",
    "#     print(\"Running LASSO feature selection with LOSO CV...\\n\")\n",
    "    \n",
    "#     # Store results across folds\n",
    "#     feature_coefficients = {feat: [] for feat in all_features}\n",
    "#     alphas_used = []\n",
    "    \n",
    "#     for test_yr in test_seasons:\n",
    "#         print(f\"Processing fold: {test_yr}\")\n",
    "        \n",
    "#         # Split data\n",
    "#         train_df = df[df['Season'] != test_yr].copy()\n",
    "#         test_df = df[\n",
    "#             (df['Season'] == test_yr) & \n",
    "#             (df['IsACCGame'] == 1) & \n",
    "#             (df['DayNum'].between(90, 120))\n",
    "#         ].copy()\n",
    "        \n",
    "#         if len(test_df) == 0:\n",
    "#             continue\n",
    "        \n",
    "#         # Prepare data\n",
    "#         X_train = train_df[all_features]\n",
    "#         y_train = train_df['HomeSpread']\n",
    "#         X_test = test_df[all_features]\n",
    "#         y_test = test_df['HomeSpread']\n",
    "        \n",
    "#         # Clean\n",
    "#         train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "#         X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "        \n",
    "#         test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "#         X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "        \n",
    "#         # CRITICAL: Standardize features (LASSO requires this)\n",
    "#         scaler = StandardScaler()\n",
    "#         X_train_scaled = scaler.fit_transform(X_train)\n",
    "#         X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "#         # Fit LASSO with cross-validation to find optimal alpha\n",
    "#         lasso_cv = LassoCV(\n",
    "#             alphas=np.logspace(-3, 1, 100),\n",
    "#             cv=5,\n",
    "#             max_iter=10000,\n",
    "#             random_state=42\n",
    "#         )\n",
    "#         lasso_cv.fit(X_train_scaled, y_train)\n",
    "        \n",
    "#         # Store coefficients\n",
    "#         for i, feat in enumerate(all_features):\n",
    "#             feature_coefficients[feat].append(lasso_cv.coef_[i])\n",
    "        \n",
    "#         alphas_used.append(lasso_cv.alpha_)\n",
    "        \n",
    "#         # Evaluate\n",
    "#         train_pred = lasso_cv.predict(X_train_scaled)\n",
    "#         test_pred = lasso_cv.predict(X_test_scaled)\n",
    "#         train_mae = mean_absolute_error(y_train, train_pred)\n",
    "#         test_mae = mean_absolute_error(y_test, test_pred)\n",
    "        \n",
    "#         n_selected = np.sum(lasso_cv.coef_ != 0)\n",
    "        \n",
    "#         print(f\"  Alpha: {lasso_cv.alpha_:.4f}\")\n",
    "#         print(f\"  Features selected: {n_selected}/{len(all_features)}\")\n",
    "#         print(f\"  Train MAE: {train_mae:.3f} | Test MAE: {test_mae:.3f}\\n\")\n",
    "    \n",
    "#     # Aggregate feature importance across folds\n",
    "#     feature_importance = []\n",
    "#     for feat in all_features:\n",
    "#         coeffs = feature_coefficients[feat]\n",
    "        \n",
    "#         feature_importance.append({\n",
    "#             'feature': feat,\n",
    "#             'mean_coef': np.mean(np.abs(coeffs)),\n",
    "#             'std_coef': np.std(np.abs(coeffs)),\n",
    "#             'times_selected': np.sum(np.array(coeffs) != 0),\n",
    "#             'mean_signed_coef': np.mean(coeffs)\n",
    "#         })\n",
    "    \n",
    "#     importance_df = pd.DataFrame(feature_importance)\n",
    "#     importance_df = importance_df.sort_values('mean_coef', ascending=False)\n",
    "    \n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\"LASSO FEATURE SELECTION SUMMARY\")\n",
    "#     print(f\"{'='*80}\")\n",
    "#     print(f\"Mean alpha used: {np.mean(alphas_used):.4f}\")\n",
    "#     print(f\"Features consistently selected (all {len(test_seasons)} folds): \"\n",
    "#           f\"{len(importance_df[importance_df['times_selected'] == len(test_seasons)])}\")\n",
    "    \n",
    "#     return importance_df, alphas_used\n",
    "\n",
    "\n",
    "# def select_stable_features(importance_df, min_selection_rate=0.8, \n",
    "#                            min_importance=0.01):\n",
    "#     \"\"\"\n",
    "#     Select features that are stable across folds\n",
    "    \n",
    "#     Args:\n",
    "#         importance_df: DataFrame from lasso_feature_selection\n",
    "#         min_selection_rate: Minimum fraction of folds where feature is selected\n",
    "#         min_importance: Minimum mean absolute coefficient\n",
    "#     \"\"\"\n",
    "    \n",
    "#     n_folds = importance_df['times_selected'].max()\n",
    "    \n",
    "#     selected = importance_df[\n",
    "#         (importance_df['times_selected'] >= min_selection_rate * n_folds) &\n",
    "#         (importance_df['mean_coef'] >= min_importance)\n",
    "#     ].copy()\n",
    "    \n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\"SELECTED FEATURES\")\n",
    "#     print(f\"{'='*80}\")\n",
    "#     print(f\"Criteria: Selected in ≥{min_selection_rate:.0%} of folds AND \"\n",
    "#           f\"mean |coef| ≥ {min_importance}\")\n",
    "#     print(f\"Result: {len(selected)}/{len(importance_df)} features selected\\n\")\n",
    "    \n",
    "#     print(\"Top 30 features by importance:\")\n",
    "#     print(selected.head(30)[['feature', 'mean_coef', 'times_selected', 'mean_signed_coef']].to_string(index=False))\n",
    "    \n",
    "#     return selected['feature'].tolist()\n",
    "\n",
    "\n",
    "# def visualize_lasso_results(importance_df, top_n=30):\n",
    "#     \"\"\"\n",
    "#     Visualize LASSO feature selection results\n",
    "#     \"\"\"\n",
    "    \n",
    "#     fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "#     # 1. Top features by mean coefficient\n",
    "#     top_features = importance_df.head(top_n)\n",
    "#     axes[0, 0].barh(range(len(top_features)), top_features['mean_coef'])\n",
    "#     axes[0, 0].set_yticks(range(len(top_features)))\n",
    "#     axes[0, 0].set_yticklabels(top_features['feature'], fontsize=8)\n",
    "#     axes[0, 0].set_xlabel('Mean |Coefficient|')\n",
    "#     axes[0, 0].set_title(f'Top {top_n} Features by LASSO Importance')\n",
    "#     axes[0, 0].invert_yaxis()\n",
    "    \n",
    "#     # 2. Selection frequency\n",
    "#     selection_counts = importance_df['times_selected'].value_counts().sort_index()\n",
    "#     axes[0, 1].bar(selection_counts.index, selection_counts.values)\n",
    "#     axes[0, 1].set_xlabel('Times Selected (out of folds)')\n",
    "#     axes[0, 1].set_ylabel('Number of Features')\n",
    "#     axes[0, 1].set_title('Feature Selection Frequency Distribution')\n",
    "    \n",
    "#     # 3. Coefficient stability\n",
    "#     axes[1, 0].scatter(importance_df['mean_coef'], \n",
    "#                        importance_df['std_coef'],\n",
    "#                        alpha=0.5)\n",
    "#     axes[1, 0].set_xlabel('Mean |Coefficient|')\n",
    "#     axes[1, 0].set_ylabel('Std |Coefficient|')\n",
    "#     axes[1, 0].set_title('Coefficient Stability')\n",
    "#     axes[1, 0].set_xscale('log')\n",
    "#     axes[1, 0].set_yscale('log')\n",
    "    \n",
    "#     # 4. Cumulative importance\n",
    "#     importance_df_sorted = importance_df.sort_values('mean_coef', ascending=False)\n",
    "#     cumsum = importance_df_sorted['mean_coef'].cumsum()\n",
    "#     cumsum_pct = cumsum / cumsum.iloc[-1] * 100\n",
    "    \n",
    "#     axes[1, 1].plot(range(len(cumsum_pct)), cumsum_pct)\n",
    "#     axes[1, 1].axhline(y=80, color='r', linestyle='--', label='80% threshold')\n",
    "#     axes[1, 1].axhline(y=90, color='orange', linestyle='--', label='90% threshold')\n",
    "#     axes[1, 1].set_xlabel('Number of Features')\n",
    "#     axes[1, 1].set_ylabel('Cumulative Importance (%)')\n",
    "#     axes[1, 1].set_title('Cumulative Feature Importance')\n",
    "#     axes[1, 1].legend()\n",
    "#     axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "#     # Find 80% and 90% thresholds\n",
    "#     n_80 = np.argmax(cumsum_pct >= 80) + 1\n",
    "#     n_90 = np.argmax(cumsum_pct >= 90) + 1\n",
    "#     print(f\"\\nFeatures needed for 80% of importance: {n_80}\")\n",
    "#     print(f\"Features needed for 90% of importance: {n_90}\")\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "    \n",
    "#     return fig\n",
    "\n",
    "\n",
    "# def compare_lasso_vs_xgboost(df, lasso_features, original_features, \n",
    "#                              test_seasons=range(2020, 2026)):\n",
    "#     \"\"\"\n",
    "#     Compare LASSO-selected features vs original best combo using XGBoost\n",
    "#     \"\"\"\n",
    "    \n",
    "#     print(f\"\\n{'='*80}\")\n",
    "#     print(f\"COMPARING LASSO FEATURES VS ORIGINAL\")\n",
    "#     print(f\"{'='*80}\\n\")\n",
    "    \n",
    "#     results = []\n",
    "    \n",
    "#     for name, features in [\n",
    "#         ('Original (elo+pom+glm)', original_features),\n",
    "#         ('LASSO selected', lasso_features),\n",
    "#         ('Combined', list(set(original_features + lasso_features)))\n",
    "#     ]:\n",
    "        \n",
    "#         print(f\"Testing: {name} ({len(features)} features)\")\n",
    "        \n",
    "#         seasonal_maes = []\n",
    "        \n",
    "#         for test_yr in test_seasons:\n",
    "#             train_df = df[df['Season'] != test_yr].copy()\n",
    "#             test_df = df[\n",
    "#                 (df['Season'] == test_yr) & \n",
    "#                 (df['IsACCGame'] == 1) & \n",
    "#                 (df['DayNum'].between(90, 120))\n",
    "#             ].copy()\n",
    "            \n",
    "#             if len(test_df) == 0:\n",
    "#                 continue\n",
    "            \n",
    "#             X_train = train_df[features]\n",
    "#             y_train = train_df['HomeSpread']\n",
    "#             X_test = test_df[features]\n",
    "#             y_test = test_df['HomeSpread']\n",
    "            \n",
    "#             # Clean\n",
    "#             train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "#             X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "            \n",
    "#             test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "#             X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "            \n",
    "#             weights = train_df.loc[train_mask, 'Season'].apply(\n",
    "#                 lambda x: 2.0 if x >= (test_yr - 3) else 1.0\n",
    "#             )\n",
    "            \n",
    "#             dtrain = xgb.DMatrix(X_train, label=y_train, weight=weights, \n",
    "#                                 feature_names=features)\n",
    "#             dtest = xgb.DMatrix(X_test, label=y_test, feature_names=features)\n",
    "            \n",
    "#             params = {\n",
    "#                 'objective': 'reg:squarederror',\n",
    "#                 'eval_metric': 'mae',\n",
    "#                 'eta': 0.05,\n",
    "#                 'max_depth': 6,\n",
    "#                 'subsample': 0.8,\n",
    "#                 'colsample_bytree': 0.8,\n",
    "#                 'gamma': 0.1,\n",
    "#                 'alpha': 0.1,\n",
    "#                 'seed': 42\n",
    "#             }\n",
    "            \n",
    "#             model = xgb.train(params, dtrain, num_boost_round=500)\n",
    "#             preds = model.predict(dtest)\n",
    "#             mae = mean_absolute_error(y_test, preds)\n",
    "#             seasonal_maes.append(mae)\n",
    "        \n",
    "#         mean_mae = np.mean(seasonal_maes)\n",
    "#         std_mae = np.std(seasonal_maes)\n",
    "        \n",
    "#         results.append({\n",
    "#             'approach': name,\n",
    "#             'num_features': len(features),\n",
    "#             'mean_mae': mean_mae,\n",
    "#             'std_mae': std_mae\n",
    "#         })\n",
    "        \n",
    "#         print(f\"  Mean MAE: {mean_mae:.3f} ± {std_mae:.3f}\\n\")\n",
    "    \n",
    "#     return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# # ============================================================================\n",
    "# # MAIN EXECUTION\n",
    "# # ============================================================================\n",
    "\n",
    "# # Step 1: Run LASSO feature selection\n",
    "# print(\"Step 1: Running LASSO feature selection...\")\n",
    "# importance_df, alphas = lasso_feature_selection(df, feature_groups)\n",
    "\n",
    "# # Step 2: Save full results\n",
    "# importance_df.to_csv('lasso_feature_importance.csv', index=False)\n",
    "# print(\"\\nFull LASSO results saved to 'lasso_feature_importance.csv'\")\n",
    "\n",
    "# # Step 3: Select stable features\n",
    "# lasso_selected = select_stable_features(\n",
    "#     importance_df, \n",
    "#     min_selection_rate=0.67,  # Selected in at least 4/6 folds\n",
    "#     min_importance=0.01\n",
    "# )\n",
    "\n",
    "# # Step 4: Visualize\n",
    "# fig = visualize_lasso_results(importance_df, top_n=40)\n",
    "\n",
    "# # Step 5: Compare with original best combo\n",
    "# original_best = (feature_groups['elo'] + \n",
    "#                  feature_groups['pom_ranking'] + \n",
    "#                  feature_groups['glm_quality'])\n",
    "\n",
    "# comparison_df = compare_lasso_vs_xgboost(\n",
    "#     df, \n",
    "#     lasso_selected, \n",
    "#     original_best\n",
    "# )\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"FINAL COMPARISON\")\n",
    "# print(\"=\"*80)\n",
    "# print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "975e18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hybrid_feature_selection(df, feature_groups, lasso_importance_df, \n",
    "#                              top_n_lasso=50, test_seasons=range(2020, 2026)):\n",
    "#     \"\"\"\n",
    "#     Use LASSO to pre-filter, then let XGBoost pick the best subset\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Get top N features from LASSO\n",
    "#     lasso_top_features = lasso_importance_df.head(top_n_lasso)['feature'].tolist()\n",
    "    \n",
    "#     # Always include the proven winners\n",
    "#     must_include = (feature_groups['elo'] + \n",
    "#                    feature_groups['pom_ranking'] + \n",
    "#                    feature_groups['glm_quality'])\n",
    "    \n",
    "#     # Combine: LASSO discoveries + proven features\n",
    "#     candidate_features = list(set(must_include + lasso_top_features))\n",
    "    \n",
    "#     print(f\"Candidate pool: {len(candidate_features)} features\")\n",
    "#     print(f\"  - Proven features: {len(must_include)}\")\n",
    "#     print(f\"  - LASSO discoveries: {len(lasso_top_features)}\")\n",
    "#     print(f\"  - Overlap: {len(set(must_include) & set(lasso_top_features))}\")\n",
    "#     print(f\"  - New from LASSO: {len(set(lasso_top_features) - set(must_include))}\\n\")\n",
    "    \n",
    "#     # Show what LASSO found that we didn't have\n",
    "#     new_features = set(lasso_top_features) - set(must_include)\n",
    "#     if new_features:\n",
    "#         print(\"New features from LASSO:\")\n",
    "#         for feat in sorted(new_features)[:15]:\n",
    "#             importance = lasso_importance_df[lasso_importance_df['feature'] == feat]['mean_coef'].values[0]\n",
    "#             print(f\"  - {feat}: {importance:.3f}\")\n",
    "    \n",
    "#     # Test this hybrid set with XGBoost\n",
    "#     seasonal_maes = []\n",
    "    \n",
    "#     for test_yr in test_seasons:\n",
    "#         train_df = df[df['Season'] != test_yr].copy()\n",
    "#         test_df = df[\n",
    "#             (df['Season'] == test_yr) & \n",
    "#             (df['IsACCGame'] == 1) & \n",
    "#             (df['DayNum'].between(90, 120))\n",
    "#         ].copy()\n",
    "        \n",
    "#         if len(test_df) == 0:\n",
    "#             continue\n",
    "        \n",
    "#         X_train = train_df[candidate_features]\n",
    "#         y_train = train_df['HomeSpread']\n",
    "#         X_test = test_df[candidate_features]\n",
    "#         y_test = test_df['HomeSpread']\n",
    "        \n",
    "#         # Clean\n",
    "#         train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "#         X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "        \n",
    "#         test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "#         X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "        \n",
    "#         weights = train_df.loc[train_mask, 'Season'].apply(\n",
    "#             lambda x: 2.0 if x >= (test_yr - 3) else 1.0\n",
    "#         )\n",
    "        \n",
    "#         dtrain = xgb.DMatrix(X_train, label=y_train, weight=weights, \n",
    "#                             feature_names=candidate_features)\n",
    "#         dtest = xgb.DMatrix(X_test, label=y_test, feature_names=candidate_features)\n",
    "        \n",
    "#         params = {\n",
    "#             'objective': 'reg:squarederror',\n",
    "#             'eval_metric': 'mae',\n",
    "#             'eta': 0.05,\n",
    "#             'max_depth': 6,\n",
    "#             'subsample': 0.8,\n",
    "#             'colsample_bytree': 0.8,\n",
    "#             'gamma': 0.1,\n",
    "#             'alpha': 0.1,\n",
    "#             'seed': 42\n",
    "#         }\n",
    "        \n",
    "#         model = xgb.train(params, dtrain, num_boost_round=500,\n",
    "#                          evals=[(dtest, 'eval')], verbose_eval=False)\n",
    "        \n",
    "#         preds = model.predict(dtest)\n",
    "#         mae = mean_absolute_error(y_test, preds)\n",
    "#         seasonal_maes.append(mae)\n",
    "        \n",
    "#         print(f\"{test_yr}: {mae:.3f}\")\n",
    "    \n",
    "#     mean_mae = np.mean(seasonal_maes)\n",
    "#     std_mae = np.std(seasonal_maes)\n",
    "    \n",
    "#     print(f\"\\nHybrid approach: {mean_mae:.3f} ± {std_mae:.3f}\")\n",
    "    \n",
    "#     return candidate_features, mean_mae\n",
    "\n",
    "\n",
    "# # Test different amounts of LASSO features\n",
    "# print(\"=\"*80)\n",
    "# print(\"TESTING HYBRID APPROACH: PROVEN + LASSO TOP-N\")\n",
    "# print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for top_n in [10, 20, 30, 50, 75]:\n",
    "#     print(f\"\\n{'='*60}\")\n",
    "#     print(f\"Testing with top {top_n} LASSO features\")\n",
    "#     print(f\"{'='*60}\")\n",
    "    \n",
    "#     hybrid_features, hybrid_mae = hybrid_feature_selection(\n",
    "#         df, feature_groups, importance_df, top_n_lasso=top_n\n",
    "#     )\n",
    "    \n",
    "#     results.append({\n",
    "#         'lasso_top_n': top_n,\n",
    "#         'total_features': len(hybrid_features),\n",
    "#         'mean_mae': hybrid_mae\n",
    "#     })\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"HYBRID RESULTS SUMMARY\")\n",
    "# print(\"=\"*80)\n",
    "# print(results_df.to_string(index=False))\n",
    "\n",
    "# # Compare with baseline\n",
    "# print(f\"\\nBaseline (elo+pom+glm): 8.199 MAE\")\n",
    "# print(f\"Best hybrid: {results_df.loc[results_df['mean_mae'].idxmin(), 'mean_mae']:.3f} MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27fc051f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL MODEL EVALUATION (LOSO CV)\n",
      "================================================================================\n",
      "2020: MAE=7.332 | Close=5.644 | Blowout=10.096 | Underpred=9.63 | Max pred=18.0\n",
      "2021: MAE=8.394 | Close=5.781 | Blowout=14.242 | Underpred=12.80 | Max pred=20.5\n",
      "2022: MAE=7.514 | Close=6.129 | Blowout=11.156 | Underpred=10.61 | Max pred=21.2\n",
      "2023: MAE=8.758 | Close=5.892 | Blowout=14.377 | Underpred=11.92 | Max pred=23.0\n",
      "2024: MAE=8.626 | Close=6.799 | Blowout=12.661 | Underpred=12.36 | Max pred=21.3\n",
      "2025: MAE=8.437 | Close=7.088 | Blowout=10.662 | Underpred=9.42 | Max pred=23.9\n",
      "\n",
      "================================================================================\n",
      "OVERALL STATISTICS\n",
      "================================================================================\n",
      "Overall MAE: 8.177 ± 0.601\n",
      "Close games (<10) MAE: 6.222\n",
      "Blowout games (≥15) MAE: 12.199\n",
      "Blowout underprediction: 11.12 points\n",
      "Max prediction ever made: 23.9\n",
      "Max actual spread: 45.0\n",
      "Coefficient of Variation: 7.35%\n",
      "\n",
      "================================================================================\n",
      "PREDICTION RANGE BY YEAR\n",
      "================================================================================\n",
      " season  max_pred  max_actual  blowout_underpred\n",
      "   2020 18.034260          34           9.629246\n",
      "   2021 20.540762          45          12.802859\n",
      "   2022 21.211872          34          10.606927\n",
      "   2023 22.970503          40          11.920517\n",
      "   2024 21.259277          34          12.364328\n",
      "   2025 23.897890          37           9.420476\n",
      "\n",
      "================================================================================\n",
      "BLOWOUT PERFORMANCE BREAKDOWN\n",
      "================================================================================\n",
      "Total blowout games (≥15): 117\n",
      "Blowout MAE: 12.199\n",
      "Close game MAE: 6.222\n",
      "Blowout MAE is 1.96x worse than close games\n"
     ]
    }
   ],
   "source": [
    "# Final optimized features (48 total)\n",
    "final_features = (\n",
    "    feature_groups['elo'] + \n",
    "    feature_groups['pom_ranking'] + \n",
    "    feature_groups['glm_quality'] +\n",
    "    \n",
    "    ['PointDiff_Diff', 'Last10_PointDiff_Diff', \n",
    "     'Last10_WinPct_Diff', 'Last5_Opp3pPct_L5_Away']\n",
    ")\n",
    "def train_and_evaluate_final_fixed(df, final_features, test_seasons=range(2020, 2026)):\n",
    "    \"\"\"\n",
    "    Train final model with proper blowout analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nFINAL MODEL EVALUATION (LOSO CV)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    seasonal_results = []\n",
    "    \n",
    "    for test_yr in test_seasons:\n",
    "        train_df = df[df['Season'] != test_yr].copy()\n",
    "        test_df = df[\n",
    "            (df['Season'] == test_yr) & \n",
    "            (df['IsACCGame'] == 1) & \n",
    "            (df['DayNum'].between(90, 120))\n",
    "        ].copy()\n",
    "        \n",
    "        if len(test_df) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_train = train_df[final_features]\n",
    "        y_train = train_df['HomeSpread']\n",
    "        X_test = test_df[final_features]\n",
    "        y_test = test_df['HomeSpread']\n",
    "        \n",
    "        # Clean\n",
    "        train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "        X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "        \n",
    "        test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "        X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "        \n",
    "        # Recency weights\n",
    "        weights = train_df.loc[train_mask, 'Season'].apply(\n",
    "            lambda x: 2.0 if x >= (test_yr - 3) else 1.0\n",
    "        )\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, weight=weights, \n",
    "                            feature_names=final_features)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test, feature_names=final_features)\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'mae',\n",
    "            'eta': 0.05,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'gamma': 0.1,\n",
    "            'alpha': 0.1,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        model = xgb.train(\n",
    "            params, dtrain,\n",
    "            num_boost_round=500,\n",
    "            evals=[(dtest, 'eval')],\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        preds = model.predict(dtest)\n",
    "        mae = mean_absolute_error(y_test, preds)\n",
    "        \n",
    "        # Fixed blowout analysis\n",
    "        y_test_array = y_test.values  # Convert to numpy array\n",
    "        blowout_mask = np.abs(y_test_array) >= 15\n",
    "        \n",
    "        if blowout_mask.sum() > 0:\n",
    "            blowout_actual = y_test_array[blowout_mask]\n",
    "            blowout_preds = preds[blowout_mask]\n",
    "            \n",
    "            blowout_mae = mean_absolute_error(blowout_actual, blowout_preds)\n",
    "            blowout_underpred = np.abs(blowout_actual).mean() - np.abs(blowout_preds).mean()\n",
    "            \n",
    "            n_blowouts = blowout_mask.sum()\n",
    "        else:\n",
    "            blowout_mae = np.nan\n",
    "            blowout_underpred = np.nan\n",
    "            n_blowouts = 0\n",
    "        \n",
    "        # Close games analysis (spread < 10)\n",
    "        close_mask = np.abs(y_test_array) < 10\n",
    "        if close_mask.sum() > 0:\n",
    "            close_mae = mean_absolute_error(y_test_array[close_mask], preds[close_mask])\n",
    "        else:\n",
    "            close_mae = np.nan\n",
    "        \n",
    "        seasonal_results.append({\n",
    "            'season': test_yr,\n",
    "            'n_games': len(y_test),\n",
    "            'n_blowouts': n_blowouts,\n",
    "            'mae': mae,\n",
    "            'close_mae': close_mae,\n",
    "            'blowout_mae': blowout_mae,\n",
    "            'blowout_underpred': blowout_underpred,\n",
    "            'max_pred': np.abs(preds).max(),\n",
    "            'max_actual': np.abs(y_test_array).max()\n",
    "        })\n",
    "        \n",
    "        print(f\"{test_yr}: MAE={mae:.3f} | Close={close_mae:.3f} | \"\n",
    "              f\"Blowout={blowout_mae:.3f} | Underpred={blowout_underpred:.2f} | \"\n",
    "              f\"Max pred={np.abs(preds).max():.1f}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(seasonal_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Overall MAE: {results_df['mae'].mean():.3f} ± {results_df['mae'].std():.3f}\")\n",
    "    print(f\"Close games (<10) MAE: {results_df['close_mae'].mean():.3f}\")\n",
    "    print(f\"Blowout games (≥15) MAE: {results_df['blowout_mae'].mean():.3f}\")\n",
    "    print(f\"Blowout underprediction: {results_df['blowout_underpred'].mean():.2f} points\")\n",
    "    print(f\"Max prediction ever made: {results_df['max_pred'].max():.1f}\")\n",
    "    print(f\"Max actual spread: {results_df['max_actual'].max():.1f}\")\n",
    "    print(f\"Coefficient of Variation: {results_df['mae'].std()/results_df['mae'].mean():.2%}\")\n",
    "    \n",
    "    # Prediction range analysis\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREDICTION RANGE BY YEAR\")\n",
    "    print(\"=\"*80)\n",
    "    print(results_df[['season', 'max_pred', 'max_actual', 'blowout_underpred']].to_string(index=False))\n",
    "    \n",
    "    return results_df, model\n",
    "\n",
    "\n",
    "results_df, final_model = train_and_evaluate_final_fixed(df, final_features)\n",
    "\n",
    "# Detailed blowout analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BLOWOUT PERFORMANCE BREAKDOWN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total blowout games (≥15): {results_df['n_blowouts'].sum()}\")\n",
    "print(f\"Blowout MAE: {results_df['blowout_mae'].mean():.3f}\")\n",
    "print(f\"Close game MAE: {results_df['close_mae'].mean():.3f}\")\n",
    "print(f\"Blowout MAE is {results_df['blowout_mae'].mean() / results_df['close_mae'].mean():.2f}x worse than close games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f555be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HYBRID: BASELINE MODEL + CALIBRATED INTERVALS\n",
      "================================================================================\n",
      "\n",
      "Finding optimal percentiles for 70% coverage...\n",
      "  15/85: Coverage=69.5% | PIW=21.38\n",
      "  12/88: Coverage=75.6% | PIW=24.16\n",
      "  10/90: Coverage=79.9% | PIW=26.15\n",
      "  8/92: Coverage=83.7% | PIW=28.37\n",
      "  5/95: Coverage=89.6% | PIW=33.48\n",
      "\n",
      "================================================================================\n",
      "RESIDUAL-BASED INTERVAL RESULTS\n",
      "================================================================================\n",
      "percentiles  coverage  min_coverage       piw    lower_q   upper_q  passed\n",
      "      15/85  0.695084      0.645161 21.382566 -11.061513 10.321053   False\n",
      "      12/88  0.755680      0.714286 24.163815 -12.346205 11.817609    True\n",
      "      10/90  0.798683      0.758065 26.149393 -13.430050 12.719343    True\n",
      "       8/92  0.837204      0.790323 28.372403 -14.718880 13.653523    True\n",
      "       5/95  0.896460      0.854839 33.480103 -17.483933 15.996169    True\n",
      "\n",
      "✓ BEST STRATEGY:\n",
      "  Percentiles: 12/88\n",
      "  Coverage: 75.6% (min: 71.4%)\n",
      "  PIW: 24.16 points\n",
      "  Quantiles: [-12.35, 11.82]\n"
     ]
    }
   ],
   "source": [
    "def hybrid_baseline_with_intervals(df, final_features, test_seasons=range(2020, 2026)):\n",
    "    \"\"\"\n",
    "    Best of both worlds:\n",
    "    - Use baseline squared error model for point predictions (8.177 MAE)\n",
    "    - Calibrate intervals from LOSO residuals\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"HYBRID: BASELINE MODEL + CALIBRATED INTERVALS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Collect residuals from LOSO CV\n",
    "    all_residuals = []\n",
    "    \n",
    "    for test_yr in test_seasons:\n",
    "        train_df = df[df['Season'] != test_yr].copy()\n",
    "        test_df = df[\n",
    "            (df['Season'] == test_yr) & \n",
    "            (df['IsACCGame'] == 1) & \n",
    "            (df['DayNum'].between(90, 120))\n",
    "        ].copy()\n",
    "        \n",
    "        if len(test_df) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_train = train_df[final_features]\n",
    "        y_train = train_df['HomeSpread']\n",
    "        X_test = test_df[final_features]\n",
    "        y_test = test_df['HomeSpread']\n",
    "        \n",
    "        # Clean\n",
    "        train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "        X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "        \n",
    "        test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "        X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "        \n",
    "        weights = train_df.loc[train_mask, 'Season'].apply(\n",
    "            lambda x: 2.0 if x >= (test_yr - 3) else 1.0\n",
    "        )\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train, weight=weights,\n",
    "                            feature_names=final_features)\n",
    "        dtest = xgb.DMatrix(X_test, feature_names=final_features)\n",
    "        \n",
    "        params = {\n",
    "            'objective': 'reg:squarederror',  # Your best model\n",
    "            'eval_metric': 'mae',\n",
    "            'eta': 0.05,\n",
    "            'max_depth': 6,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'gamma': 0.1,\n",
    "            'alpha': 0.1,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        model = xgb.train(params, dtrain, num_boost_round=500, verbose_eval=False)\n",
    "        preds = model.predict(dtest)\n",
    "        \n",
    "        # Collect residuals\n",
    "        residuals = y_test.values - preds\n",
    "        all_residuals.extend(residuals)\n",
    "    \n",
    "    all_residuals = np.array(all_residuals)\n",
    "    \n",
    "    # Test different percentiles to achieve 70% coverage\n",
    "    print(\"\\nFinding optimal percentiles for 70% coverage...\")\n",
    "    \n",
    "    percentile_pairs = [\n",
    "        (15, 85),\n",
    "        (12, 88),\n",
    "        (10, 90),\n",
    "        (8, 92),\n",
    "        (5, 95),\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for lower_pct, upper_pct in percentile_pairs:\n",
    "        lower_q = np.percentile(all_residuals, lower_pct)\n",
    "        upper_q = np.percentile(all_residuals, upper_pct)\n",
    "        \n",
    "        # Test coverage\n",
    "        coverages = []\n",
    "        piws = []\n",
    "        \n",
    "        for test_yr in test_seasons:\n",
    "            train_df = df[df['Season'] != test_yr].copy()\n",
    "            test_df = df[\n",
    "                (df['Season'] == test_yr) & \n",
    "                (df['IsACCGame'] == 1) & \n",
    "                (df['DayNum'].between(90, 120))\n",
    "            ].copy()\n",
    "            \n",
    "            if len(test_df) == 0:\n",
    "                continue\n",
    "            \n",
    "            X_train = train_df[final_features]\n",
    "            y_train = train_df['HomeSpread']\n",
    "            X_test = test_df[final_features]\n",
    "            y_test = test_df['HomeSpread']\n",
    "            \n",
    "            train_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())\n",
    "            X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
    "            \n",
    "            test_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())\n",
    "            X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
    "            \n",
    "            weights = train_df.loc[train_mask, 'Season'].apply(\n",
    "                lambda x: 2.0 if x >= (test_yr - 3) else 1.0\n",
    "            )\n",
    "            \n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, weight=weights,\n",
    "                                feature_names=final_features)\n",
    "            dtest = xgb.DMatrix(X_test, feature_names=final_features)\n",
    "            \n",
    "            params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'eval_metric': 'mae',\n",
    "                'eta': 0.05,\n",
    "                'max_depth': 6,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'gamma': 0.1,\n",
    "                'alpha': 0.1,\n",
    "                'seed': 42\n",
    "            }\n",
    "            \n",
    "            model = xgb.train(params, dtrain, num_boost_round=500, verbose_eval=False)\n",
    "            preds = model.predict(dtest)\n",
    "            \n",
    "            # Apply intervals\n",
    "            ci_lb = preds + lower_q\n",
    "            ci_ub = preds + upper_q\n",
    "            \n",
    "            # Evaluate\n",
    "            y_test_array = y_test.values\n",
    "            coverage = np.mean((y_test_array >= ci_lb) & (y_test_array <= ci_ub))\n",
    "            piw = np.mean(ci_ub - ci_lb)\n",
    "            \n",
    "            coverages.append(coverage)\n",
    "            piws.append(piw)\n",
    "        \n",
    "        results.append({\n",
    "            'percentiles': f\"{lower_pct}/{upper_pct}\",\n",
    "            'coverage': np.mean(coverages),\n",
    "            'min_coverage': np.min(coverages),\n",
    "            'piw': np.mean(piws),\n",
    "            'lower_q': lower_q,\n",
    "            'upper_q': upper_q,\n",
    "            'passed': np.mean(coverages) >= 0.70\n",
    "        })\n",
    "        \n",
    "        print(f\"  {lower_pct}/{upper_pct}: Coverage={np.mean(coverages):.1%} | PIW={np.mean(piws):.2f}\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESIDUAL-BASED INTERVAL RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Find best passing strategy\n",
    "    passing = results_df[results_df['passed']]\n",
    "    if len(passing) > 0:\n",
    "        best = passing.loc[passing['piw'].idxmin()]\n",
    "        print(\"\\n✓ BEST STRATEGY:\")\n",
    "        print(f\"  Percentiles: {best['percentiles']}\")\n",
    "        print(f\"  Coverage: {best['coverage']:.1%} (min: {best['min_coverage']:.1%})\")\n",
    "        print(f\"  PIW: {best['piw']:.2f} points\")\n",
    "        print(f\"  Quantiles: [{best['lower_q']:.2f}, {best['upper_q']:.2f}]\")\n",
    "        \n",
    "        return best\n",
    "    else:\n",
    "        print(\"\\n⚠️ No strategy achieved 70% coverage\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Run hybrid approach\n",
    "best_interval_strategy = hybrid_baseline_with_intervals(df, final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d6025e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_path = \"march-machine-learning-mania-2025.zip\"\n",
    "with zipfile.ZipFile(zip_path) as z:\n",
    "    with z.open('MTeamSpellings.csv') as f:\n",
    "        spellings = pd.read_csv(f)\n",
    "import re\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = name.lower()\n",
    "    name = re.sub(r'[^a-z0-9 ]', ' ', name)   # remove punctuation, replace with space\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()  # collapse whitespace\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca27394",
   "metadata": {},
   "outputs": [],
   "source": [
    "spellings['norm'] = spellings['TeamNameSpelling'].apply(normalize_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6e5bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_2026 = pd.read_csv('data/team_box_26.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e86c5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_2026['norm'] = season_2026['team_location'].apply(normalize_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8752082",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_2026 = season_2026.merge(spellings[['norm', 'TeamID']], on='norm', how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5549854",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = season_2026['team_location'].str.contains('Miami') & \\\n",
    "       ~season_2026['team_location'].str.contains(r'\\(OH\\)')\n",
    "\n",
    "season_2026.loc[mask, 'TeamID'] = 1274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb14e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "torvik = pd.read_csv('data/barttorvik_15_26.csv')\n",
    "torvik['norm'] = torvik['Team'].apply(normalize_name)\n",
    "torvik = torvik.drop(['Unnamed: 0.1', 'Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "torvik['Date'] = pd.to_datetime(torvik['Date'])\n",
    "torvik['Season'] = torvik['Date'].dt.year.astype('int32')\n",
    "torvik.loc[torvik['Date'].dt.month >= 11, 'Season'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1330a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torvik_26 = torvik[torvik['Season']==2026]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd8d70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'season_2026' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 388\u001b[39m\n\u001b[32m    383\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df, competition_games\n\u001b[32m    386\u001b[39m \u001b[38;5;66;03m# Run the complete pipeline\u001b[39;00m\n\u001b[32m    387\u001b[39m df_2026_all, df_2026_competition = create_2026_features_complete(\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     \u001b[43mseason_2026\u001b[49m,\n\u001b[32m    389\u001b[39m     torvik_26,\n\u001b[32m    390\u001b[39m     final_features\n\u001b[32m    391\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m    394\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✓ FEATURE ENGINEERING COMPLETE\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'season_2026' is not defined"
     ]
    }
   ],
   "source": [
    "def create_2026_features_complete(df_2026_raw, torvik_26, final_features):\n",
    "    \"\"\"\n",
    "    Complete feature engineering for 2026 submission\n",
    "    Uses Torvik data + calculates Elo, GLM, and momentum features\n",
    "    POM features use placeholders (TODO: scrape POM ratings)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"CREATING ALL 48 FEATURES FOR 2026 SUBMISSION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 1: Restructure raw game data\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\nStep 1: Restructuring game data...\")\n",
    "    \n",
    "    # Separate home and away\n",
    "    home_games = df_2026_raw[df_2026_raw['team_home_away'] == 'home'].copy()\n",
    "    away_games = df_2026_raw[df_2026_raw['team_home_away'] == 'away'].copy()\n",
    "    \n",
    "    # Merge\n",
    "    games = home_games.merge(\n",
    "        away_games,\n",
    "        on=['game_id', 'season', 'game_date'],\n",
    "        suffixes=('_home', '_away')\n",
    "    )\n",
    "    \n",
    "    # Create base dataframe\n",
    "    df = pd.DataFrame({\n",
    "        'Season': 2026,\n",
    "        'game_id': games['game_id'],\n",
    "        'game_date': pd.to_datetime(games['game_date']),\n",
    "        'HomeTeamID': games['TeamID_home'],\n",
    "        'AwayTeamID': games['TeamID_away'],\n",
    "        'HTeamName': games['team_name_home'].str.lower(),\n",
    "        'ATeamName': games['team_name_away'].str.lower(),\n",
    "        'HomeScore': pd.to_numeric(games['team_score_home'], errors='coerce'),\n",
    "        'AwayScore': pd.to_numeric(games['team_score_away'], errors='coerce'),\n",
    "    })\n",
    "    \n",
    "    df['HomeSpread'] = df['HomeScore'] - df['AwayScore']\n",
    "    \n",
    "    # Calculate DayNum\n",
    "    season_start = df['game_date'].min()\n",
    "    df['DayNum'] = (df['game_date'] - season_start).dt.days\n",
    "    \n",
    "    # Sort by date\n",
    "    df = df.sort_values(['game_date', 'game_id']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"  Total games: {len(df)}\")\n",
    "    print(f\"  Date range: {df['game_date'].min().date()} to {df['game_date'].max().date()}\")\n",
    "    print(f\"  DayNum range: {df['DayNum'].min()} to {df['DayNum'].max()}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 2: Add conference information (for ACC filter)\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\nStep 2: Adding conference information...\")\n",
    "    \n",
    "    # Normalize team names for matching\n",
    "    torvik_26['norm'] = torvik_26['Team'].str.lower().str.replace(' ', ' ')\n",
    "    \n",
    "    # Create conference lookup\n",
    "    conf_lookup = dict(zip(torvik_26['norm'], torvik_26['Conf']))\n",
    "    \n",
    "    df['HomeConf'] = df['HTeamName'].map(conf_lookup)\n",
    "    df['AwayConf'] = df['ATeamName'].map(conf_lookup)\n",
    "    df['IsACCGame'] = ((df['HomeConf'] == 'ACC') & (df['AwayConf'] == 'ACC')).astype(int)\n",
    "    \n",
    "    acc_games = df[df['IsACCGame'] == 1]\n",
    "    acc_games_competition = acc_games[acc_games['DayNum'].between(90, 120)]\n",
    "    \n",
    "    print(f\"  ACC games total: {len(acc_games)}\")\n",
    "    print(f\"  ACC games in competition window (days 90-120): {len(acc_games_competition)}\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 3: Calculate Elo features (17 features)\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\nStep 3: Calculating Elo ratings...\")\n",
    "    \n",
    "    # Initialize Elo tracking\n",
    "    team_elo_history = {}\n",
    "    \n",
    "    # Elo parameters (match your historical calculation)\n",
    "    K_FACTOR = 32\n",
    "    HOME_ADVANTAGE = 100\n",
    "    \n",
    "    for idx in range(len(df)):\n",
    "        game = df.iloc[idx]\n",
    "        home_team = game['HomeTeamID']\n",
    "        away_team = game['AwayTeamID']\n",
    "        \n",
    "        # Initialize teams if first appearance\n",
    "        if home_team not in team_elo_history:\n",
    "            team_elo_history[home_team] = [1500]\n",
    "        if away_team not in team_elo_history:\n",
    "            team_elo_history[away_team] = [1500]\n",
    "        \n",
    "        # Get current Elo\n",
    "        home_elo = team_elo_history[home_team][-1]\n",
    "        away_elo = team_elo_history[away_team][-1]\n",
    "        \n",
    "        # Store current Elo\n",
    "        df.at[idx, 'Elo_Last_Home'] = home_elo\n",
    "        df.at[idx, 'Elo_Last_Away'] = away_elo\n",
    "        df.at[idx, 'Elo_Last_Diff'] = home_elo - away_elo\n",
    "        \n",
    "        # Calculate statistics from history\n",
    "        home_history = team_elo_history[home_team]\n",
    "        away_history = team_elo_history[away_team]\n",
    "        \n",
    "        df.at[idx, 'Elo_Mean_Home'] = np.mean(home_history)\n",
    "        df.at[idx, 'Elo_Median_Home'] = np.median(home_history)\n",
    "        df.at[idx, 'Elo_Std_Home'] = np.std(home_history) if len(home_history) > 1 else 0\n",
    "        df.at[idx, 'Elo_Min_Home'] = np.min(home_history)\n",
    "        df.at[idx, 'Elo_Max_Home'] = np.max(home_history)\n",
    "        \n",
    "        df.at[idx, 'Elo_Mean_Away'] = np.mean(away_history)\n",
    "        df.at[idx, 'Elo_Median_Away'] = np.median(away_history)\n",
    "        df.at[idx, 'Elo_Std_Away'] = np.std(away_history) if len(away_history) > 1 else 0\n",
    "        df.at[idx, 'Elo_Min_Away'] = np.min(away_history)\n",
    "        df.at[idx, 'Elo_Max_Away'] = np.max(away_history)\n",
    "        \n",
    "        # Calculate trend (slope of Elo over time)\n",
    "        if len(home_history) >= 3:\n",
    "            home_trend = np.polyfit(range(len(home_history)), home_history, 1)[0]\n",
    "        else:\n",
    "            home_trend = 0\n",
    "            \n",
    "        if len(away_history) >= 3:\n",
    "            away_trend = np.polyfit(range(len(away_history)), away_history, 1)[0]\n",
    "        else:\n",
    "            away_trend = 0\n",
    "        \n",
    "        df.at[idx, 'Elo_Trend_Home'] = home_trend\n",
    "        df.at[idx, 'Elo_Trend_Away'] = away_trend\n",
    "        \n",
    "        # Differentials\n",
    "        df.at[idx, 'Elo_Mean_Diff'] = df.at[idx, 'Elo_Mean_Home'] - df.at[idx, 'Elo_Mean_Away']\n",
    "        df.at[idx, 'Elo_Trend_Diff'] = home_trend - away_trend\n",
    "        \n",
    "        # Update Elo for next game (if game has been played)\n",
    "        if pd.notna(game['HomeScore']) and pd.notna(game['AwayScore']):\n",
    "            margin = game['HomeScore'] - game['AwayScore']\n",
    "            \n",
    "            # Expected outcome\n",
    "            expected_home = 1 / (1 + 10 ** ((away_elo - home_elo - HOME_ADVANTAGE) / 400))\n",
    "            \n",
    "            # Actual outcome\n",
    "            actual_home = 1 if margin > 0 else 0\n",
    "            \n",
    "            # Margin of victory multiplier\n",
    "            mov_multiplier = np.log(abs(margin) + 1)\n",
    "            \n",
    "            # Update\n",
    "            home_elo_new = home_elo + K_FACTOR * mov_multiplier * (actual_home - expected_home)\n",
    "            away_elo_new = away_elo - K_FACTOR * mov_multiplier * (actual_home - expected_home)\n",
    "            \n",
    "            team_elo_history[home_team].append(home_elo_new)\n",
    "            team_elo_history[away_team].append(away_elo_new)\n",
    "    \n",
    "    print(f\"  ✓ Elo features calculated for {len(team_elo_history)} teams\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 4: Add POM ranking features (24 features) - PLACEHOLDERS\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\nStep 4: Adding POM ranking features...\")\n",
    "    print(\"  ⚠️ USING PLACEHOLDER VALUES - TODO: SCRAPE POM RATINGS\")\n",
    "    \n",
    "    pom_features = [\n",
    "        'Home_POM_Rank', 'Home_POM_RankDay', 'Away_POM_Rank', 'Away_POM_RankDay',\n",
    "        'POM_RankDiff', 'Home_POM_Strength', 'Away_POM_Strength', 'POM_StrengthDiff',\n",
    "        'Home_POM_LogStrength', 'Away_POM_LogStrength', 'Home_POM_Strength2',\n",
    "        'Away_POM_Strength2', 'Home_POM_IsTop25', 'Away_POM_IsTop25',\n",
    "        'Home_POM_IsTop50', 'Away_POM_IsTop50', 'POM_BothTop25', 'POM_BothTop50',\n",
    "        'POM_RankDiff_Squared', 'RankDiff_Magnitude', 'IsHugeMismatch',\n",
    "        'IsBigMismatch', 'Elite_vs_Weak', 'Weak_vs_Elite'\n",
    "    ]\n",
    "    \n",
    "    for feat in pom_features:\n",
    "        df[feat] = 0  # Placeholder\n",
    "    \n",
    "    print(f\"  ⚠️ Created {len(pom_features)} placeholder POM features\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 5: Calculate GLM quality features (3 features)\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\nStep 5: Calculating GLM quality features...\")\n",
    "    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    for idx in range(len(df)):\n",
    "        game = df.iloc[idx]\n",
    "        \n",
    "        # Get all completed games before this one\n",
    "        past_games = df.iloc[:idx]\n",
    "        past_games = past_games.dropna(subset=['HomeScore', 'AwayScore'])\n",
    "        \n",
    "        if len(past_games) < 20: \n",
    "            df.at[idx, 'GLM_Quality_Home'] = 0\n",
    "            df.at[idx, 'GLM_Quality_Away'] = 0\n",
    "            df.at[idx, 'GLM_Quality_Diff'] = 0\n",
    "            continue\n",
    "        \n",
    "        # Get unique teams\n",
    "        teams = sorted(list(set(past_games['HomeTeamID'].unique()) | \n",
    "                           set(past_games['AwayTeamID'].unique())))\n",
    "        team_to_idx = {team: i for i, team in enumerate(teams)}\n",
    "        \n",
    "        # Create design matrix\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for _, g in past_games.iterrows():\n",
    "            team_vec = [0] * len(teams)\n",
    "            \n",
    "            if g['HomeTeamID'] in team_to_idx:\n",
    "                team_vec[team_to_idx[g['HomeTeamID']]] = 1\n",
    "            if g['AwayTeamID'] in team_to_idx:\n",
    "                team_vec[team_to_idx[g['AwayTeamID']]] = -1\n",
    "            \n",
    "            X.append(team_vec)\n",
    "            y.append(1 if g['HomeScore'] > g['AwayScore'] else 0)\n",
    "        \n",
    "\n",
    "        lr = LogisticRegression(penalty='l2', C=1.0, max_iter=1000, solver='lbfgs')\n",
    "        lr.fit(X, y)\n",
    "        \n",
    "        # Get quality for current game's teams\n",
    "        home_team = game['HomeTeamID']\n",
    "        away_team = game['AwayTeamID']\n",
    "        \n",
    "        home_quality = lr.coef_[0][team_to_idx[home_team]] if home_team in team_to_idx else 0\n",
    "        away_quality = lr.coef_[0][team_to_idx[away_team]] if away_team in team_to_idx else 0\n",
    "        \n",
    "        df.at[idx, 'GLM_Quality_Home'] = home_quality\n",
    "        df.at[idx, 'GLM_Quality_Away'] = away_quality\n",
    "        df.at[idx, 'GLM_Quality_Diff'] = home_quality - away_quality\n",
    "\n",
    "    \n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 6: Calculate momentum/season features (4 LASSO features)\n",
    "    # =========================================================================\n",
    "    \n",
    "    \n",
    "    # Add box score stats for 3PT% calculation\n",
    "    games_expanded = home_games.merge(\n",
    "        away_games,\n",
    "        on=['game_id', 'season', 'game_date'],\n",
    "        suffixes=('_home', '_away')\n",
    "    )\n",
    "    \n",
    "    box_score_lookup = {}\n",
    "    for _, g in games_expanded.iterrows():\n",
    "        game_id = g['game_id']\n",
    "        box_score_lookup[game_id] = {\n",
    "            'home_3p_pct': pd.to_numeric(g['three_point_field_goal_pct_home'], errors='coerce'),\n",
    "            'away_3p_pct': pd.to_numeric(g['three_point_field_goal_pct_away'], errors='coerce')\n",
    "        }\n",
    "    \n",
    "    for idx in range(len(df)):\n",
    "        game = df.iloc[idx]\n",
    "        home_team = game['HomeTeamID']\n",
    "        away_team = game['AwayTeamID']\n",
    "        \n",
    "        # Get past completed games for each team\n",
    "        past_games = df.iloc[:idx].dropna(subset=['HomeScore', 'AwayScore'])\n",
    "        \n",
    "        # Home team history\n",
    "        home_games_past = past_games[\n",
    "            (past_games['HomeTeamID'] == home_team) | \n",
    "            (past_games['AwayTeamID'] == home_team)\n",
    "        ]\n",
    "        \n",
    "        # Away team history\n",
    "        away_games_past = past_games[\n",
    "            (past_games['HomeTeamID'] == away_team) | \n",
    "            (past_games['AwayTeamID'] == away_team)\n",
    "        ]\n",
    "        \n",
    "        # Calculate point differentials\n",
    "        home_diffs = []\n",
    "        for _, g in home_games_past.iterrows():\n",
    "            if g['HomeTeamID'] == home_team:\n",
    "                home_diffs.append(g['HomeScore'] - g['AwayScore'])\n",
    "            else:\n",
    "                home_diffs.append(g['AwayScore'] - g['HomeScore'])\n",
    "        \n",
    "        away_diffs = []\n",
    "        for _, g in away_games_past.iterrows():\n",
    "            if g['HomeTeamID'] == away_team:\n",
    "                away_diffs.append(g['HomeScore'] - g['AwayScore'])\n",
    "            else:\n",
    "                away_diffs.append(g['AwayScore'] - g['HomeScore'])\n",
    "        \n",
    "        # 1. PointDiff_Diff (season average)\n",
    "        home_avg = np.mean(home_diffs) if len(home_diffs) > 0 else 0\n",
    "        away_avg = np.mean(away_diffs) if len(away_diffs) > 0 else 0\n",
    "        df.at[idx, 'PointDiff_Diff'] = home_avg - away_avg\n",
    "        \n",
    "        # 2. Last10_PointDiff_Diff\n",
    "        home_l10 = np.mean(home_diffs[-10:]) if len(home_diffs) >= 10 else home_avg\n",
    "        away_l10 = np.mean(away_diffs[-10:]) if len(away_diffs) >= 10 else away_avg\n",
    "        df.at[idx, 'Last10_PointDiff_Diff'] = home_l10 - away_l10\n",
    "        \n",
    "        # 3. Last10_WinPct_Diff\n",
    "        home_wins_l10 = sum(1 for d in home_diffs[-10:] if d > 0) if len(home_diffs) >= 10 else sum(1 for d in home_diffs if d > 0)\n",
    "        away_wins_l10 = sum(1 for d in away_diffs[-10:] if d > 0) if len(away_diffs) >= 10 else sum(1 for d in away_diffs if d > 0)\n",
    "        \n",
    "        home_wp = home_wins_l10 / min(10, len(home_diffs)) if len(home_diffs) > 0 else 0\n",
    "        away_wp = away_wins_l10 / min(10, len(away_diffs)) if len(away_diffs) > 0 else 0\n",
    "        df.at[idx, 'Last10_WinPct_Diff'] = home_wp - away_wp\n",
    "        \n",
    "        # 4. Last5_Opp3pPct_L5_Away (away team's opponents' 3PT% in last 5 games)\n",
    "        away_l5_games = away_games_past.tail(5)\n",
    "        opp_3p_pcts = []\n",
    "        \n",
    "        for _, g in away_l5_games.iterrows():\n",
    "            if g['game_id'] in box_score_lookup:\n",
    "                if g['HomeTeamID'] == away_team:\n",
    "                    # Away team was home, opponent was away\n",
    "                    opp_3p_pcts.append(box_score_lookup[g['game_id']]['away_3p_pct'])\n",
    "                else:\n",
    "                    # Away team was away, opponent was home\n",
    "                    opp_3p_pcts.append(box_score_lookup[g['game_id']]['home_3p_pct'])\n",
    "        \n",
    "        # Filter out NaN values\n",
    "        opp_3p_pcts = [x for x in opp_3p_pcts if pd.notna(x)]\n",
    "        df.at[idx, 'Last5_Opp3pPct_L5_Away'] = np.mean(opp_3p_pcts) if len(opp_3p_pcts) > 0 else 0.35  # Default to 35%\n",
    "    \n",
    "    print(f\"  ✓ Momentum features calculated\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 7: Verify all features present\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FEATURE VERIFICATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    missing = [f for f in final_features if f not in df.columns]\n",
    "    present = [f for f in final_features if f in df.columns]\n",
    "    \n",
    "    print(f\"Features present: {len(present)}/{len(final_features)}\")\n",
    "    \n",
    "    if len(missing) > 0:\n",
    "        print(f\"\\n⚠️ Missing {len(missing)} features:\")\n",
    "        for f in missing:\n",
    "            print(f\"  - {f}\")\n",
    "        print(\"\\nCannot proceed with predictions until all features are present!\")\n",
    "        return None, None\n",
    "    \n",
    "    print(\"✓ All 48 features present!\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # STEP 8: Filter for competition games\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPETITION GAMES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    competition_games = df[\n",
    "        (df['IsACCGame'] == 1) & \n",
    "        (df['DayNum'].between(90, 120))\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Total ACC games in competition window: {len(competition_games)}\")\n",
    "    \n",
    "    if len(competition_games) == 0:\n",
    "        print(\"⚠️ WARNING: No games found in competition window!\")\n",
    "        print(\"Check your DayNum calculation and ACC game identification\")\n",
    "    else:\n",
    "        print(f\"Date range: {competition_games['game_date'].min().date()} to {competition_games['game_date'].max().date()}\")\n",
    "        print(f\"\\nSample games:\")\n",
    "        print(competition_games[['game_date', 'HTeamName', 'ATeamName', 'DayNum']].head(10).to_string(index=False))\n",
    "    \n",
    "    return df, competition_games\n",
    "\n",
    "\n",
    "# Run the complete pipeline\n",
    "df_2026_all, df_2026_competition = create_2026_features_complete(\n",
    "    season_2026,\n",
    "    torvik_26,\n",
    "    final_features\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total 2026 games processed: {len(df_2026_all)}\")\n",
    "print(f\"Competition games ready: {len(df_2026_competition)}\")\n",
    "print(\"\\nNext step: Run production model to generate predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
